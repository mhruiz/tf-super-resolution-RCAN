import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import argparse

'''
This script allows the user to plot how are the metrics changing during the training.
It has 2 arguments:
    - the file path, which can be a csv file generated by the callback 'Save_Training_Evolution' or a txt file with model.fit() verbose output
    - a list for every metric to show. Optional if the file path is a csv file (if no list is given, it will plot every metric)
'''

def see_graphs_from_verbose(files, elements_to_take, parameter, comparison=False, names=[], title=None, *args):

    raise NotImplementedError('')

    if type(files) != list:
        files = [files]

    train = []
    validation = []
    
    plt.figure()

    if not comparison:

        for file, n_take in zip(files, elements_to_take):
            train_current_file = []
            val_current_file = []
            with open(file) as f:
                for line in f.readlines():
                    if 'val_' + parameter in line:
                        values = list(map(lambda x: float(x.split(' ')[0]), line.split(parameter+': ')[1:]))
                        train_current_file.append(values[0])
                        val_current_file.append(values[1])

            if n_take == 0:
                # Take all elements
                train.extend(train_current_file)
                validation.extend(val_current_file)
            elif n_take > 0:
                # Take the first X elements
                train.extend(train_current_file[:n_take])
                validation.extend(val_current_file[:n_take])
            else:
                # Take the last X elements
                train.extend(train_current_file[n_take:])
                validation.extend(val_current_file[n_take:])
                    
        plt.plot(train, label='Training')
        plt.plot(validation, label='Validation')

    else:
        for i, (file, n_take) in enumerate(zip(files, elements_to_take)):
            train_current_file = []
            val_current_file = []
            with open(file) as f:
                for line in f.readlines():
                    if 'val_' + parameter in line:
                        values = list(map(lambda x: float(x.split(' ')[0]), line.split(parameter+': ')[1:]))
                        train_current_file.append(values[0])
                        val_current_file.append(values[1])

            if n_take == 0:
                # Take all elements
                train = train_current_file
                validation = val_current_file
            elif n_take > 0:
                # Take the first X elements
                train = train_current_file[:n_take]
                validation = val_current_file[:n_take]
            else:
                # Take the last X elements
                train = train_current_file[n_take:]
                validation = val_current_file[n_take:]
                    
            plt.plot(train, label='Training -- ' + (('file ' + str(i)) if names==[] else names[i]))
            plt.plot(validation, label='Validation -- ' + (('file ' + str(i)) if names==[] else names[i]))

    plt.legend(loc='best')
    plt.xlabel('Num epochs')
    plt.ylabel(parameter)
    if title is None:
        plt.title('Train vs validation: '+parameter)
    else:
        plt.title(title + ' - Train vs validation: ' + parameter)
    
    if args != [] and len(args) == 2:
        plt.ylim(args[0], args[1])
    
    plt.grid(True)

    plt.show(block=False)
    
def see_graphs_from_dataframe(dataframes, elements_to_take, parameter, comparison=False, names=[], title=None, *args):
    train = []
    validation = []
    
    if type(dataframes) != list:
        dataframes = [dataframes]
    
    dataframes = [df.rename(columns={'val_val_loss':'val_loss'}) for df in dataframes]

    plt.figure()

    if not comparison:
        for dataframe, n_take in zip(dataframes, elements_to_take):

            if parameter in dataframe.columns:

                if n_take == 0:
                    # Take all elements
                    train.extend(dataframe[parameter].tolist())
                    validation.extend(dataframe['val_'+parameter].tolist())
                elif n_take > 0:
                    # Take the first X elements
                    train.extend(dataframe[parameter].tolist()[:n_take])
                    validation.extend(dataframe['val_'+parameter].tolist()[:n_take])
                else:
                    # Take the last X elements
                    train.extend(dataframe[parameter].tolist()[n_take:])
                    validation.extend(dataframe['val_'+parameter].tolist()[n_take:])

        plt.plot(train, label='Training')
        plt.plot(validation, label='Validation ')

    else:
        for i, (dataframe, n_take) in enumerate(zip(dataframes, elements_to_take)):

            if parameter in dataframe.columns:

                if n_take == 0:
                    # Take all elements
                    train = dataframe[parameter].tolist()
                    validation = dataframe['val_'+parameter].tolist()
                elif n_take > 0:
                    # Take the first X elements
                    train = dataframe[parameter].tolist()[:n_take]
                    validation = dataframe['val_'+parameter].tolist()[:n_take]
                else:
                    # Take the last X elements
                    train = dataframe[parameter].tolist()[n_take:]
                    validation = dataframe['val_'+parameter].tolist()[n_take:]

                plt.plot(train, label='Training - ' + (('file ' + str(i)) if names==[] else names[i]))
                plt.plot(validation, label='Validation - ' + (('file ' + str(i)) if names==[] else names[i]))

    plt.legend(loc='best')
    plt.xlabel('Num epochs')
    plt.ylabel(parameter)
    if title is None:
        plt.title('Train vs validation: '+parameter)
    else:
        plt.title(title + ' - Train vs validation: ' + parameter)
    
    if args != [] and len(args) == 2:
        plt.ylim(args[0], args[1])
    
    plt.grid(True)

    plt.show(block=False)


# Define arguments
parser = argparse.ArgumentParser(description='Show metric evolution')

parser.add_argument('files',
                    type=str,
                    nargs='+',
                    help='Specify the path to the file(s) that contains the metrics evolution. If there are more than one file, ' + \
                         'it will concatenate them as an one training, except if \'--compare\' is specified')

parser.add_argument('-t', '--take',
                    type=int,
                    nargs='+',
                    help='Specify how many points have to be extracted from each file. Positive value means to take the first X values, ' + \
                         'negative means to take the last X values. 0 means keep all values. All values from all files will be taken by default',
                    default=[])

parser.add_argument('-m', '--metrics', 
                    type=str,
                    nargs='+', 
                    help='Specify which metrics have to be shown', 
                    default=[])

parser.add_argument('-s', '--scale',
                    nargs='+',
                    help='Specify y-scale on plot windows for all metrics',
                    default=[])

parser.add_argument('--names',
                    nargs='+',
                    help='Specify the names for the differents models to compare. Only applied if \'--compare\' is specifed',
                    default=[])

parser.add_argument('--compare', 
                    action='store_true', # Returns true if this argument was given
                    help='The indicated files belong to different training sessions. Their graphs will be displayed together for comparison', 
                    default=False)

parser.add_argument('--title',
                    nargs='+',
                    type=str,
                    help='Specify title for every plot figure',
                    default='')

# Read arguments

args = parser.parse_args()

# Read arguments ------------------------------------
file_names = args.files

# Check if all files have the same extension
file_exts = set(x.split('.')[-1] for x in file_names)
assert len(file_exts) == 1, 'All the files must have the same file extension: .txt for verbose output, or .csv for training_evolution callback'

elements_to_take = args.take
if elements_to_take == []:
    elements_to_take = [0] * len(file_names)
else:
    assert len(file_names) == len(elements_to_take)

names = args.names

assert names == [] and not args.compare or len(file_names) == len(names) and args.compare

metrics = args.metrics

title = ' '.join(args.title) if args.title != '' else None

y_scale = args.scale
assert len(y_scale) == 0 or len(y_scale) == 2

if 'csv' in file_exts:
    
    dataframes = [pd.read_csv(file_name) for file_name in file_names]
    all_metrics = list(set([x for i in range(len(dataframes)) for x in dataframes[i].columns if 'val_' not in x and x != 'lr']))
    
    if metrics != []:
        assert all(m in all_metrics for m in metrics), 'Some metrics are not present in this file. \n' + \
            'Existing metrics: ' + ', '.join(all_metrics) + '\n' + \
                'Specified metrics: ' + ', '.join(metrics)
    
        for m in metrics:
            see_graphs_from_dataframe(dataframes, elements_to_take, m, args.compare, names, title, *y_scale)
    
    else:
        for m in all_metrics:
            see_graphs_from_dataframe(dataframes, elements_to_take, m, args.compare, names, title, *y_scale)

else:
    for m in metrics:
        see_graphs_from_verbose(file_names, elements_to_take, m, args.compare, names, title, *y_scale)

plt.show()
