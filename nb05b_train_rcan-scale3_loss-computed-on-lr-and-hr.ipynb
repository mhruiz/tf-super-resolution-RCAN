{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "three-framework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "----------------------------------\n",
      "Num images for training: 800\n",
      "Num images for validating: 100\n",
      "----------------------------------\n",
      "Smallest image in train dataset: 1116\n",
      "Smallest image in validation dataset: 1356\n",
      "----------------------------------\n",
      "Biggest image in train dataset: 2040\n",
      "Biggest image in validation dataset: 2040\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# GPU memory limit\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Import own modules\n",
    "import lib.training_loops as training_loops\n",
    "import lib.custom_callbacks as callbacks\n",
    "import lib.PrepareDataset as dt\n",
    "import lib.constants as ctes\n",
    "import lib.RCAN as RCAN\n",
    "\n",
    "######################################################################################\n",
    "# DEFINE ARGUMENTS\n",
    "\n",
    "# Load datasets from CSV files\n",
    "TRAINING_DATASETS = [pd.read_csv('data/0_csvs/DIV2K_train_HR.csv')]\n",
    "VALIDATION_DATASETS = [pd.read_csv('data/0_csvs/DIV2K_valid_HR.csv')]\n",
    "\n",
    "# Define dataset parameters\n",
    "TRAINING_COLOR_MODE = ctes.COLOR_MODE.RGB\n",
    "TRAINING_SCALE = 3\n",
    "TRAINING_BATCH_SIZE = 16\n",
    "TRAINING_PATCH_SIZE = 48\n",
    "TRAINING_DATA_AUG = True\n",
    "TRAINING_SHUFFLE = True\n",
    "TRAINING_REPEAT = 200 # ----------------- Según la implementación en TF 1.13, se valida cada 10.000 training steps. Al ser 800 imágenes de entrenamiento y un batch de 16, hay 50 steps por época\n",
    "                      #                   Hay que realizar 10.000 iteraciones antes de validar. Estas son equivalentes a 200 épocas de entrenamiento sin validación, osea, repetir 200 veces el dataset\n",
    "TRAINING_NORMALIZE = False\n",
    "\n",
    "VALIDATION_COLOR_MODE = TRAINING_COLOR_MODE\n",
    "VALIDATION_SCALE = TRAINING_SCALE\n",
    "VALIDATION_BATCH_SIZE = 1\n",
    "VALIDATION_PATCH_SIZE = None\n",
    "VALIDATION_DATA_AUG = False\n",
    "VALIDATION_SHUFFLE = False\n",
    "VALIDATION_REPEAT = None\n",
    "VALIDATION_NORMALIZE = False\n",
    "\n",
    "FILENAME = 'nb05b_train_rcan-scale3_loss-computed-on-lr-and-hr'\n",
    "\n",
    "# Get model info from file name\n",
    "info_from_script_name = FILENAME.split('_') \n",
    "\n",
    "model_structure_name = info_from_script_name[2].upper() \n",
    "\n",
    "model_name = info_from_script_name[3:]            \n",
    "model_name = ('_'.join(['model'] + model_name)).split('.')[0]\n",
    "model_name_for_metrics = model_structure_name + '_' + model_name         \n",
    "\n",
    "BASE_MODEL_PATH = 'TRAINED_MODELS_NEW/'\n",
    "BASE_METRIC_PATH = 'TRAINING_METRIC_EVOLUTIONS_NEW/'\n",
    "\n",
    "if not os.path.exists(BASE_MODEL_PATH):\n",
    "    os.mkdir(BASE_MODEL_PATH)\n",
    "if not os.path.exists(BASE_METRIC_PATH):\n",
    "    os.mkdir(BASE_METRIC_PATH)\n",
    "\n",
    "save_path = BASE_MODEL_PATH + model_structure_name + '/'\n",
    "save_metrics_path = BASE_METRIC_PATH\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "# Load datasets as PrepareDataset objects\n",
    "train = dt.PrepareDataset(dataframes=TRAINING_DATASETS, \n",
    "                          channel_mode=TRAINING_COLOR_MODE, \n",
    "                          scale=TRAINING_SCALE,\n",
    "                          batch_size=TRAINING_BATCH_SIZE, \n",
    "                          patch_size=TRAINING_PATCH_SIZE,\n",
    "                          data_augmentation=TRAINING_DATA_AUG, \n",
    "                          shuffle=TRAINING_SHUFFLE, \n",
    "                          repeat=TRAINING_REPEAT,\n",
    "                          normalize=TRAINING_NORMALIZE)\n",
    "\n",
    "val = dt.PrepareDataset(dataframes=VALIDATION_DATASETS, \n",
    "                        channel_mode=VALIDATION_COLOR_MODE, \n",
    "                        scale=VALIDATION_SCALE, \n",
    "                        batch_size=VALIDATION_BATCH_SIZE,\n",
    "                        patch_size=VALIDATION_PATCH_SIZE, \n",
    "                        data_augmentation=VALIDATION_DATA_AUG,\n",
    "                        shuffle=VALIDATION_SHUFFLE,\n",
    "                        repeat=VALIDATION_REPEAT,\n",
    "                        normalize=VALIDATION_NORMALIZE)\n",
    "\n",
    "print('----------------------------------')\n",
    "print('Num images for training:', sum(x.shape[0] for x in TRAINING_DATASETS))\n",
    "print('Num images for validating:', sum(x.shape[0] for x in VALIDATION_DATASETS))\n",
    "print('----------------------------------')\n",
    "\n",
    "def aux_fn(datasets, condition_fn):\n",
    "    return condition_fn(condition_fn(cv2.imread(row.path).shape[1:-1]) for i in range(len(datasets)) for row in datasets[i].itertuples())\n",
    "\n",
    "print('Smallest image in train dataset:', aux_fn(TRAINING_DATASETS, min))\n",
    "smallest_validation_size = aux_fn(VALIDATION_DATASETS, min)\n",
    "print('Smallest image in validation dataset:', smallest_validation_size)\n",
    "print('----------------------------------')\n",
    "print('Biggest image in train dataset:', aux_fn(TRAINING_DATASETS, max))\n",
    "biggest_validation_image = aux_fn(VALIDATION_DATASETS, max)\n",
    "print('Biggest image in validation dataset:', biggest_validation_image)\n",
    "print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "previous-decline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Num Conv layers: 814\n",
      "   Num ReLU layers: 200\n",
      "   Num Add layers: 211\n",
      "Total layers: 1225\n",
      "Num layers: 1631\n",
      "Num parameters: 15629283\n",
      "Num trainable variables: 1628\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "NUM_RESIDUAL_GROUPS = 10\n",
    "NUM_RESIDUAL_BLOCKS = 20\n",
    "NUM_FEATURES = 64\n",
    "KERNEL_SIZE = 3\n",
    "REDUCTION = 16\n",
    "NUM_IMAGE_CHANNELS = TRAINING_COLOR_MODE\n",
    "SCALE = TRAINING_SCALE\n",
    "NORMALIZATION = False\n",
    "TRAINING_LOOP = training_loops.Train_Loss_LR_and_HR\n",
    "\n",
    "model = RCAN.get_RCAN(NUM_RESIDUAL_GROUPS,\n",
    "                        NUM_RESIDUAL_BLOCKS,\n",
    "                        NUM_FEATURES,\n",
    "                        KERNEL_SIZE,\n",
    "                        REDUCTION,\n",
    "                        NUM_IMAGE_CHANNELS,\n",
    "                        SCALE,\n",
    "                        NORMALIZATION,\n",
    "                        TRAINING_LOOP)\n",
    "\n",
    "# model.summary()\n",
    "types = {\n",
    "    'Conv': tf.keras.layers.Conv2D,\n",
    "    'ReLU': tf.keras.layers.ReLU,\n",
    "    'Add': tf.keras.layers.Add \n",
    "}\n",
    "\n",
    "total_num = 0\n",
    "\n",
    "for k in types:\n",
    "    num = len(list(filter(lambda x: type(x) == types[k], model.layers)))\n",
    "    print('   Num', k, 'layers:', num)\n",
    "    total_num += num\n",
    "print('Total layers:', total_num)\n",
    "\n",
    "print('Num layers:', len(model.layers))\n",
    "print('Num parameters:', model.count_params())\n",
    "\n",
    "print('Num trainable variables:', sum(len(l.trainable_variables) for l in model.layers))\n",
    "\n",
    "# Save model structure to JSON file\n",
    "if os.path.exists(save_path + model_name + '.json'):\n",
    "    os.remove(save_path + model_name + '.json')\n",
    "with open(save_path + model_name + '.json', 'w') as json_file:\n",
    "    json_file.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "transparent-pound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts training\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 6305s 631ms/step - psnr: 31.8405 - ssim: 0.8353 - mse: 145.0464 - mae: 5.6835 - sobel_loss: 3063.5457 - loss: 6.9644 - val_psnr: 29.8974 - val_ssim: 0.8546 - val_mse: 107.0000 - val_mae: 4.8800 - val_sobel_loss: 2338.6277 - val_val_loss: 6.1242\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 6290s 629ms/step - psnr: 33.1728 - ssim: 0.8597 - mse: 115.6387 - mae: 4.9133 - sobel_loss: 2507.0559 - loss: 5.6967 - val_psnr: 30.4723 - val_ssim: 0.8653 - val_mse: 95.3700 - val_mae: 4.5200 - val_sobel_loss: 2076.2886 - val_val_loss: 5.6739\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 6289s 629ms/step - psnr: 33.4777 - ssim: 0.8652 - mse: 109.5270 - mae: 4.7513 - sobel_loss: 2355.2957 - loss: 5.4751 - val_psnr: 30.6826 - val_ssim: 0.8685 - val_mse: 91.0400 - val_mae: 4.4400 - val_sobel_loss: 1971.6112 - val_val_loss: 5.5085\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 6269s 627ms/step - psnr: 33.6524 - ssim: 0.8690 - mse: 105.0575 - mae: 4.6298 - sobel_loss: 2248.7639 - loss: 5.3304 - val_psnr: 30.7871 - val_ssim: 0.8708 - val_mse: 89.3400 - val_mae: 4.3600 - val_sobel_loss: 1929.4135 - val_val_loss: 5.4762\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 6270s 627ms/step - psnr: 33.7794 - ssim: 0.8707 - mse: 102.6773 - mae: 4.5681 - sobel_loss: 2190.8247 - loss: 5.2572 - val_psnr: 30.7874 - val_ssim: 0.8706 - val_mse: 88.8300 - val_mae: 4.4100 - val_sobel_loss: 1916.8866 - val_val_loss: 5.4772\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 6269s 627ms/step - psnr: 33.8351 - ssim: 0.8719 - mse: 101.2213 - mae: 4.5385 - sobel_loss: 2153.1567 - loss: 5.2086 - val_psnr: 30.8786 - val_ssim: 0.8717 - val_mse: 87.1100 - val_mae: 4.3400 - val_sobel_loss: 1878.6748 - val_val_loss: 5.4032\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 6274s 627ms/step - psnr: 33.8900 - ssim: 0.8730 - mse: 100.0331 - mae: 4.5041 - sobel_loss: 2123.9807 - loss: 5.1672 - val_psnr: 30.9219 - val_ssim: 0.8730 - val_mse: 86.3700 - val_mae: 4.2600 - val_sobel_loss: 1859.0094 - val_val_loss: 5.3764\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 6278s 628ms/step - psnr: 33.9628 - ssim: 0.8738 - mse: 98.5116 - mae: 4.4666 - sobel_loss: 2088.6865 - loss: 5.1210 - val_psnr: 30.9048 - val_ssim: 0.8734 - val_mse: 86.8700 - val_mae: 4.2500 - val_sobel_loss: 1870.9186 - val_val_loss: 5.4007\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 6280s 628ms/step - psnr: 33.9872 - ssim: 0.8744 - mse: 98.1570 - mae: 4.4621 - sobel_loss: 2075.5828 - loss: 5.1067 - val_psnr: 30.9814 - val_ssim: 0.8741 - val_mse: 85.2500 - val_mae: 4.1800 - val_sobel_loss: 1832.6479 - val_val_loss: 5.4211\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 6280s 628ms/step - psnr: 34.0248 - ssim: 0.8749 - mse: 97.6513 - mae: 4.4418 - sobel_loss: 2063.3108 - loss: 5.0861 - val_psnr: 30.9766 - val_ssim: 0.8743 - val_mse: 85.4900 - val_mae: 4.1800 - val_sobel_loss: 1838.7563 - val_val_loss: 5.3507\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 6280s 628ms/step - psnr: 34.0750 - ssim: 0.8755 - mse: 96.7110 - mae: 4.4231 - sobel_loss: 2042.3324 - loss: 5.0622 - val_psnr: 31.0053 - val_ssim: 0.8747 - val_mse: 84.9100 - val_mae: 4.1700 - val_sobel_loss: 1822.3142 - val_val_loss: 5.3610\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 6284s 628ms/step - psnr: 34.0712 - ssim: 0.8759 - mse: 96.2652 - mae: 4.4175 - sobel_loss: 2031.8726 - loss: 5.0473 - val_psnr: 30.9924 - val_ssim: 0.8745 - val_mse: 85.2300 - val_mae: 4.1800 - val_sobel_loss: 1830.3716 - val_val_loss: 5.3945\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 6302s 630ms/step - psnr: 34.0842 - ssim: 0.8762 - mse: 95.8546 - mae: 4.4069 - sobel_loss: 2021.4587 - loss: 5.0360 - val_psnr: 31.0337 - val_ssim: 0.8754 - val_mse: 84.2800 - val_mae: 4.1600 - val_sobel_loss: 1804.7781 - val_val_loss: 5.3577\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 6295s 630ms/step - psnr: 34.1367 - ssim: 0.8767 - mse: 95.5814 - mae: 4.3939 - sobel_loss: 2014.8652 - loss: 5.0211 - val_psnr: 31.0425 - val_ssim: 0.8753 - val_mse: 84.2500 - val_mae: 4.1500 - val_sobel_loss: 1807.2400 - val_val_loss: 5.3235\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 6300s 630ms/step - psnr: 34.1124 - ssim: 0.8763 - mse: 95.5332 - mae: 4.3962 - sobel_loss: 2012.5560 - loss: 5.0213 - val_psnr: 31.0585 - val_ssim: 0.8756 - val_mse: 84.0500 - val_mae: 4.1400 - val_sobel_loss: 1802.3785 - val_val_loss: 5.3156\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 6297s 630ms/step - psnr: 34.1959 - ssim: 0.8773 - mse: 94.2292 - mae: 4.3561 - sobel_loss: 1984.0762 - loss: 4.9791 - val_psnr: 31.0529 - val_ssim: 0.8756 - val_mse: 84.0900 - val_mae: 4.1600 - val_sobel_loss: 1803.2327 - val_val_loss: 5.3738\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 6317s 632ms/step - psnr: 34.1983 - ssim: 0.8776 - mse: 94.2467 - mae: 4.3496 - sobel_loss: 1982.2152 - loss: 4.9790 - val_psnr: 31.0796 - val_ssim: 0.8758 - val_mse: 83.5900 - val_mae: 4.1500 - val_sobel_loss: 1791.4083 - val_val_loss: 5.3335\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 6337s 634ms/step - psnr: 34.2038 - ssim: 0.8779 - mse: 93.4170 - mae: 4.3462 - sobel_loss: 1963.3510 - loss: 4.9633 - val_psnr: 31.0623 - val_ssim: 0.8759 - val_mse: 83.8500 - val_mae: 4.1400 - val_sobel_loss: 1798.2856 - val_val_loss: 5.3026\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 6325s 633ms/step - psnr: 34.1819 - ssim: 0.8775 - mse: 94.2802 - mae: 4.3681 - sobel_loss: 1980.7216 - loss: 4.9825 - val_psnr: 31.0600 - val_ssim: 0.8756 - val_mse: 83.7700 - val_mae: 4.1400 - val_sobel_loss: 1794.4314 - val_val_loss: 5.2998\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 6332s 633ms/step - psnr: 34.2003 - ssim: 0.8777 - mse: 93.5684 - mae: 4.3481 - sobel_loss: 1966.3934 - loss: 4.9661 - val_psnr: 31.0849 - val_ssim: 0.8761 - val_mse: 83.4100 - val_mae: 4.1100 - val_sobel_loss: 1785.9854 - val_val_loss: 5.3190\n",
      "Epoch 0020 --- Learning rate reduced to: 4.999999873689376e-05\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 6292s 629ms/step - psnr: 34.3401 - ssim: 0.8795 - mse: 92.1502 - mae: 4.2965 - sobel_loss: 1930.9542 - loss: 4.8703 - val_psnr: 31.1538 - val_ssim: 0.8772 - val_mse: 82.2000 - val_mae: 4.1000 - val_sobel_loss: 1757.7887 - val_val_loss: 5.2677\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 6296s 630ms/step - psnr: 34.3322 - ssim: 0.8794 - mse: 91.8661 - mae: 4.3007 - sobel_loss: 1924.8716 - loss: 4.8721 - val_psnr: 31.1586 - val_ssim: 0.8772 - val_mse: 82.1800 - val_mae: 4.0900 - val_sobel_loss: 1757.7314 - val_val_loss: 5.2978\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 6292s 629ms/step - psnr: 34.3377 - ssim: 0.8796 - mse: 91.1644 - mae: 4.2857 - sobel_loss: 1907.5272 - loss: 4.8569 - val_psnr: 31.1690 - val_ssim: 0.8774 - val_mse: 82.0400 - val_mae: 4.0700 - val_sobel_loss: 1753.5396 - val_val_loss: 5.2641\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 6289s 629ms/step - psnr: 34.3542 - ssim: 0.8799 - mse: 90.9232 - mae: 4.2787 - sobel_loss: 1902.5063 - loss: 4.8494 - val_psnr: 31.1712 - val_ssim: 0.8774 - val_mse: 82.0500 - val_mae: 4.0900 - val_sobel_loss: 1754.1545 - val_val_loss: 5.2505\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 6295s 630ms/step - psnr: 34.3656 - ssim: 0.8800 - mse: 90.8755 - mae: 4.2743 - sobel_loss: 1900.2958 - loss: 4.8439 - val_psnr: 31.1783 - val_ssim: 0.8774 - val_mse: 81.9400 - val_mae: 4.0800 - val_sobel_loss: 1751.7499 - val_val_loss: 5.2643\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 6303s 630ms/step - psnr: 34.3669 - ssim: 0.8801 - mse: 90.8060 - mae: 4.2658 - sobel_loss: 1897.6940 - loss: 4.8415 - val_psnr: 31.1850 - val_ssim: 0.8774 - val_mse: 81.7900 - val_mae: 4.0700 - val_sobel_loss: 1747.5936 - val_val_loss: 5.2605\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 6306s 631ms/step - psnr: 34.3514 - ssim: 0.8799 - mse: 91.0149 - mae: 4.2834 - sobel_loss: 1901.6031 - loss: 4.8504 - val_psnr: 31.1802 - val_ssim: 0.8776 - val_mse: 81.8200 - val_mae: 4.0800 - val_sobel_loss: 1748.3964 - val_val_loss: 5.2732\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 6307s 631ms/step - psnr: 34.3652 - ssim: 0.8801 - mse: 91.0047 - mae: 4.2806 - sobel_loss: 1900.8105 - loss: 4.8468 - val_psnr: 31.1853 - val_ssim: 0.8774 - val_mse: 81.7600 - val_mae: 4.0700 - val_sobel_loss: 1747.0587 - val_val_loss: 5.2557\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 6307s 631ms/step - psnr: 34.3992 - ssim: 0.8805 - mse: 90.2826 - mae: 4.2598 - sobel_loss: 1886.6410 - loss: 4.8301 - val_psnr: 31.1865 - val_ssim: 0.8776 - val_mse: 81.6500 - val_mae: 4.0700 - val_sobel_loss: 1745.1101 - val_val_loss: 5.2698\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 6312s 631ms/step - psnr: 34.4001 - ssim: 0.8806 - mse: 90.0508 - mae: 4.2491 - sobel_loss: 1880.9655 - loss: 4.8223 - val_psnr: 31.1928 - val_ssim: 0.8778 - val_mse: 81.7400 - val_mae: 4.0700 - val_sobel_loss: 1746.0511 - val_val_loss: 5.2616\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 6314s 631ms/step - psnr: 34.4262 - ssim: 0.8808 - mse: 89.9045 - mae: 4.2448 - sobel_loss: 1875.1724 - loss: 4.8150 - val_psnr: 31.1697 - val_ssim: 0.8772 - val_mse: 82.0500 - val_mae: 4.0900 - val_sobel_loss: 1753.8081 - val_val_loss: 5.2462\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 6351s 635ms/step - psnr: 34.4129 - ssim: 0.8807 - mse: 89.9328 - mae: 4.2484 - sobel_loss: 1876.6569 - loss: 4.8168 - val_psnr: 31.1827 - val_ssim: 0.8776 - val_mse: 81.8000 - val_mae: 4.0700 - val_sobel_loss: 1748.6256 - val_val_loss: 5.2692\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 6379s 638ms/step - psnr: 34.4078 - ssim: 0.8809 - mse: 90.2300 - mae: 4.2532 - sobel_loss: 1882.0200 - loss: 4.8196 - val_psnr: 31.1891 - val_ssim: 0.8778 - val_mse: 81.8700 - val_mae: 4.0700 - val_sobel_loss: 1749.9092 - val_val_loss: 5.2529\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 6316s 632ms/step - psnr: 34.3937 - ssim: 0.8805 - mse: 90.5592 - mae: 4.2660 - sobel_loss: 1889.0920 - loss: 4.8343 - val_psnr: 31.2023 - val_ssim: 0.8780 - val_mse: 81.4300 - val_mae: 4.0700 - val_sobel_loss: 1739.6001 - val_val_loss: 5.2352\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 6412s 641ms/step - psnr: 34.3783 - ssim: 0.8806 - mse: 89.7407 - mae: 4.2510 - sobel_loss: 1874.3459 - loss: 4.8212 - val_psnr: 31.1948 - val_ssim: 0.8778 - val_mse: 81.6100 - val_mae: 4.0700 - val_sobel_loss: 1743.1842 - val_val_loss: 5.2609\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 6416s 642ms/step - psnr: 34.4127 - ssim: 0.8809 - mse: 90.1073 - mae: 4.2491 - sobel_loss: 1878.2660 - loss: 4.8210 - val_psnr: 31.2005 - val_ssim: 0.8778 - val_mse: 81.5000 - val_mae: 4.0700 - val_sobel_loss: 1740.3560 - val_val_loss: 5.2601\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 6363s 636ms/step - psnr: 34.4277 - ssim: 0.8809 - mse: 89.7945 - mae: 4.2459 - sobel_loss: 1871.9041 - loss: 4.8140 - val_psnr: 31.1859 - val_ssim: 0.8777 - val_mse: 81.9000 - val_mae: 4.0700 - val_sobel_loss: 1749.1353 - val_val_loss: 5.2602\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 6363s 636ms/step - psnr: 34.4275 - ssim: 0.8810 - mse: 89.2140 - mae: 4.2357 - sobel_loss: 1859.7852 - loss: 4.8042 - val_psnr: 31.2040 - val_ssim: 0.8779 - val_mse: 81.4800 - val_mae: 4.0700 - val_sobel_loss: 1740.6542 - val_val_loss: 5.2524\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 6367s 637ms/step - psnr: 34.4285 - ssim: 0.8814 - mse: 89.0770 - mae: 4.2266 - sobel_loss: 1855.3101 - loss: 4.7978 - val_psnr: 31.2041 - val_ssim: 0.8781 - val_mse: 81.4400 - val_mae: 4.0700 - val_sobel_loss: 1739.4287 - val_val_loss: 5.2550\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 6386s 639ms/step - psnr: 34.4720 - ssim: 0.8815 - mse: 89.2113 - mae: 4.2319 - sobel_loss: 1858.9758 - loss: 4.7964 - val_psnr: 31.2123 - val_ssim: 0.8781 - val_mse: 81.3400 - val_mae: 4.0700 - val_sobel_loss: 1736.6077 - val_val_loss: 5.2412\n",
      "Epoch 0040 --- Learning rate reduced to: 2.499999936844688e-05\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 6385s 638ms/step - psnr: 34.4511 - ssim: 0.8820 - mse: 88.4046 - mae: 4.2151 - sobel_loss: 1839.3702 - loss: 4.7592 - val_psnr: 31.2222 - val_ssim: 0.8783 - val_mse: 81.1900 - val_mae: 4.0700 - val_sobel_loss: 1732.0548 - val_val_loss: 5.2283\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 6382s 638ms/step - psnr: 34.4901 - ssim: 0.8822 - mse: 88.5351 - mae: 4.2168 - sobel_loss: 1841.7275 - loss: 4.7564 - val_psnr: 31.2045 - val_ssim: 0.8782 - val_mse: 81.2700 - val_mae: 4.0700 - val_sobel_loss: 1736.3556 - val_val_loss: 5.2343\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 6382s 638ms/step - psnr: 34.5167 - ssim: 0.8823 - mse: 88.1890 - mae: 4.2064 - sobel_loss: 1833.5247 - loss: 4.7479 - val_psnr: 31.2326 - val_ssim: 0.8785 - val_mse: 81.0600 - val_mae: 4.0700 - val_sobel_loss: 1728.9669 - val_val_loss: 5.2337\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 6395s 640ms/step - psnr: 34.4709 - ssim: 0.8818 - mse: 88.3498 - mae: 4.2159 - sobel_loss: 1836.7581 - loss: 4.7600 - val_psnr: 31.2383 - val_ssim: 0.8785 - val_mse: 80.8500 - val_mae: 4.0700 - val_sobel_loss: 1725.5297 - val_val_loss: 5.2320\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 6397s 640ms/step - psnr: 34.4712 - ssim: 0.8823 - mse: 88.0831 - mae: 4.2069 - sobel_loss: 1830.6710 - loss: 4.7518 - val_psnr: 31.2366 - val_ssim: 0.8785 - val_mse: 80.9300 - val_mae: 4.0700 - val_sobel_loss: 1726.3788 - val_val_loss: 5.2229\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 6400s 640ms/step - psnr: 34.4998 - ssim: 0.8826 - mse: 87.4518 - mae: 4.1872 - sobel_loss: 1819.4189 - loss: 4.7326 - val_psnr: 31.2286 - val_ssim: 0.8786 - val_mse: 81.1700 - val_mae: 4.0700 - val_sobel_loss: 1732.8771 - val_val_loss: 5.2224\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 6413s 641ms/step - psnr: 34.4977 - ssim: 0.8825 - mse: 87.5313 - mae: 4.1930 - sobel_loss: 1819.4332 - loss: 4.7352 - val_psnr: 31.2451 - val_ssim: 0.8786 - val_mse: 80.8000 - val_mae: 4.0600 - val_sobel_loss: 1725.0177 - val_val_loss: 5.2226\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 6415s 642ms/step - psnr: 34.5184 - ssim: 0.8828 - mse: 87.1598 - mae: 4.1852 - sobel_loss: 1811.6820 - loss: 4.7259 - val_psnr: 31.2437 - val_ssim: 0.8785 - val_mse: 80.9500 - val_mae: 4.0600 - val_sobel_loss: 1727.0565 - val_val_loss: 5.2186\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 6419s 642ms/step - psnr: 34.4859 - ssim: 0.8822 - mse: 87.7163 - mae: 4.2007 - sobel_loss: 1822.7756 - loss: 4.7426 - val_psnr: 31.2468 - val_ssim: 0.8786 - val_mse: 80.7900 - val_mae: 4.0700 - val_sobel_loss: 1723.8037 - val_val_loss: 5.2235\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 6422s 642ms/step - psnr: 34.5008 - ssim: 0.8823 - mse: 87.8261 - mae: 4.1970 - sobel_loss: 1823.4104 - loss: 4.7419 - val_psnr: 31.2457 - val_ssim: 0.8788 - val_mse: 80.8000 - val_mae: 4.0700 - val_sobel_loss: 1724.2981 - val_val_loss: 5.2299\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 6417s 642ms/step - psnr: 34.5266 - ssim: 0.8826 - mse: 87.7540 - mae: 4.1930 - sobel_loss: 1822.3682 - loss: 4.7384 - val_psnr: 31.2495 - val_ssim: 0.8786 - val_mse: 80.7700 - val_mae: 4.0700 - val_sobel_loss: 1723.3199 - val_val_loss: 5.2371\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 6422s 642ms/step - psnr: 34.5018 - ssim: 0.8825 - mse: 87.5828 - mae: 4.1924 - sobel_loss: 1820.2742 - loss: 4.7377 - val_psnr: 31.2396 - val_ssim: 0.8786 - val_mse: 80.9800 - val_mae: 4.0700 - val_sobel_loss: 1727.8008 - val_val_loss: 5.2339\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 6428s 643ms/step - psnr: 34.5199 - ssim: 0.8828 - mse: 87.0843 - mae: 4.1847 - sobel_loss: 1809.6698 - loss: 4.7255 - val_psnr: 31.2486 - val_ssim: 0.8787 - val_mse: 80.7900 - val_mae: 4.0600 - val_sobel_loss: 1722.8575 - val_val_loss: 5.2144\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 6424s 642ms/step - psnr: 34.5223 - ssim: 0.8827 - mse: 87.1675 - mae: 4.1800 - sobel_loss: 1810.0938 - loss: 4.7241 - val_psnr: 31.2440 - val_ssim: 0.8786 - val_mse: 80.8000 - val_mae: 4.0700 - val_sobel_loss: 1723.6781 - val_val_loss: 5.2264\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 6411s 641ms/step - psnr: 34.5423 - ssim: 0.8829 - mse: 87.0388 - mae: 4.1812 - sobel_loss: 1808.1292 - loss: 4.7209 - val_psnr: 31.2523 - val_ssim: 0.8788 - val_mse: 80.7100 - val_mae: 4.0700 - val_sobel_loss: 1721.4452 - val_val_loss: 5.2159\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 6289s 629ms/step - psnr: 34.5383 - ssim: 0.8829 - mse: 86.9541 - mae: 4.1786 - sobel_loss: 1804.8173 - loss: 4.7199 - val_psnr: 31.2438 - val_ssim: 0.8787 - val_mse: 80.8100 - val_mae: 4.0700 - val_sobel_loss: 1724.7014 - val_val_loss: 5.2188\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 6295s 630ms/step - psnr: 34.5094 - ssim: 0.8828 - mse: 87.0820 - mae: 4.1892 - sobel_loss: 1808.9990 - loss: 4.7290 - val_psnr: 31.2373 - val_ssim: 0.8787 - val_mse: 81.0800 - val_mae: 4.0700 - val_sobel_loss: 1730.0273 - val_val_loss: 5.2302\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 6297s 630ms/step - psnr: 34.4968 - ssim: 0.8827 - mse: 87.0860 - mae: 4.1868 - sobel_loss: 1809.4038 - loss: 4.7324 - val_psnr: 31.2473 - val_ssim: 0.8787 - val_mse: 80.8300 - val_mae: 4.0700 - val_sobel_loss: 1724.2120 - val_val_loss: 5.2174\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 6309s 631ms/step - psnr: 34.5564 - ssim: 0.8832 - mse: 86.6233 - mae: 4.1644 - sobel_loss: 1797.8088 - loss: 4.7073 - val_psnr: 31.2512 - val_ssim: 0.8787 - val_mse: 80.8200 - val_mae: 4.0700 - val_sobel_loss: 1723.5493 - val_val_loss: 5.2274\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 6316s 632ms/step - psnr: 34.5237 - ssim: 0.8830 - mse: 87.0390 - mae: 4.1777 - sobel_loss: 1808.5242 - loss: 4.7222 - val_psnr: 31.2485 - val_ssim: 0.8787 - val_mse: 80.7500 - val_mae: 4.0700 - val_sobel_loss: 1723.3907 - val_val_loss: 5.2254\n",
      "Epoch 0060 --- Learning rate reduced to: 1.249999968422344e-05\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 6338s 634ms/step - psnr: 34.5372 - ssim: 0.8832 - mse: 86.6767 - mae: 4.1708 - sobel_loss: 1797.3342 - loss: 4.7014 - val_psnr: 31.2646 - val_ssim: 0.8789 - val_mse: 80.5700 - val_mae: 4.0700 - val_sobel_loss: 1718.1138 - val_val_loss: 5.2161\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 6356s 636ms/step - psnr: 34.5639 - ssim: 0.8833 - mse: 86.3907 - mae: 4.1590 - sobel_loss: 1791.6650 - loss: 4.6933 - val_psnr: 31.2567 - val_ssim: 0.8789 - val_mse: 80.6900 - val_mae: 4.0700 - val_sobel_loss: 1721.4915 - val_val_loss: 5.2133\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 6370s 637ms/step - psnr: 34.5283 - ssim: 0.8833 - mse: 86.5769 - mae: 4.1708 - sobel_loss: 1794.8634 - loss: 4.7024 - val_psnr: 31.2590 - val_ssim: 0.8789 - val_mse: 80.6300 - val_mae: 4.0700 - val_sobel_loss: 1719.1025 - val_val_loss: 5.2115\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 6392s 639ms/step - psnr: 34.5380 - ssim: 0.8832 - mse: 86.7436 - mae: 4.1662 - sobel_loss: 1798.5134 - loss: 4.7030 - val_psnr: 31.2626 - val_ssim: 0.8789 - val_mse: 80.5100 - val_mae: 4.0700 - val_sobel_loss: 1716.2767 - val_val_loss: 5.2120\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 6406s 641ms/step - psnr: 34.5392 - ssim: 0.8834 - mse: 86.3815 - mae: 4.1648 - sobel_loss: 1789.0664 - loss: 4.6944 - val_psnr: 31.2578 - val_ssim: 0.8790 - val_mse: 80.6800 - val_mae: 4.0600 - val_sobel_loss: 1721.4382 - val_val_loss: 5.2069\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 6413s 641ms/step - psnr: 34.5364 - ssim: 0.8837 - mse: 86.0960 - mae: 4.1604 - sobel_loss: 1784.7653 - loss: 4.6880 - val_psnr: 31.2619 - val_ssim: 0.8790 - val_mse: 80.5400 - val_mae: 4.0700 - val_sobel_loss: 1717.8030 - val_val_loss: 5.2107\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 6411s 641ms/step - psnr: 34.5533 - ssim: 0.8833 - mse: 86.3437 - mae: 4.1599 - sobel_loss: 1789.9094 - loss: 4.6946 - val_psnr: 31.2620 - val_ssim: 0.8790 - val_mse: 80.5500 - val_mae: 4.0700 - val_sobel_loss: 1717.2416 - val_val_loss: 5.2043\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 6413s 641ms/step - psnr: 34.5500 - ssim: 0.8833 - mse: 86.0433 - mae: 4.1571 - sobel_loss: 1783.3896 - loss: 4.6897 - val_psnr: 31.2630 - val_ssim: 0.8789 - val_mse: 80.5500 - val_mae: 4.0600 - val_sobel_loss: 1716.7965 - val_val_loss: 5.2073\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 6420s 642ms/step - psnr: 34.5547 - ssim: 0.8836 - mse: 86.3992 - mae: 4.1612 - sobel_loss: 1790.9730 - loss: 4.6963 - val_psnr: 31.2596 - val_ssim: 0.8789 - val_mse: 80.6300 - val_mae: 4.0700 - val_sobel_loss: 1719.4023 - val_val_loss: 5.2094\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 6426s 643ms/step - psnr: 34.5379 - ssim: 0.8832 - mse: 86.7973 - mae: 4.1715 - sobel_loss: 1799.0413 - loss: 4.7066 - val_psnr: 31.2637 - val_ssim: 0.8790 - val_mse: 80.6200 - val_mae: 4.0700 - val_sobel_loss: 1718.3671 - val_val_loss: 5.2096\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 6282s 628ms/step - psnr: 34.5305 - ssim: 0.8832 - mse: 86.6144 - mae: 4.1687 - sobel_loss: 1794.9114 - loss: 4.7030 - val_psnr: 31.2669 - val_ssim: 0.8789 - val_mse: 80.5200 - val_mae: 4.0700 - val_sobel_loss: 1715.9178 - val_val_loss: 5.2198\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 6266s 627ms/step - psnr: 34.5699 - ssim: 0.8838 - mse: 85.9958 - mae: 4.1530 - sobel_loss: 1782.6212 - loss: 4.6822 - val_psnr: 31.2584 - val_ssim: 0.8789 - val_mse: 80.6600 - val_mae: 4.0600 - val_sobel_loss: 1720.4220 - val_val_loss: 5.2172\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 6257s 626ms/step - psnr: 34.5575 - ssim: 0.8839 - mse: 86.0374 - mae: 4.1519 - sobel_loss: 1784.6196 - loss: 4.6857 - val_psnr: 31.2581 - val_ssim: 0.8789 - val_mse: 80.6400 - val_mae: 4.0600 - val_sobel_loss: 1718.8175 - val_val_loss: 5.2059\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 6260s 626ms/step - psnr: 34.5695 - ssim: 0.8839 - mse: 85.5911 - mae: 4.1416 - sobel_loss: 1775.5964 - loss: 4.6755 - val_psnr: 31.2622 - val_ssim: 0.8790 - val_mse: 80.5800 - val_mae: 4.0700 - val_sobel_loss: 1717.9758 - val_val_loss: 5.2067\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 6260s 626ms/step - psnr: 34.5296 - ssim: 0.8837 - mse: 85.9398 - mae: 4.1515 - sobel_loss: 1780.1772 - loss: 4.6879 - val_psnr: 31.2650 - val_ssim: 0.8789 - val_mse: 80.5900 - val_mae: 4.0600 - val_sobel_loss: 1717.8986 - val_val_loss: 5.2080\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 6261s 626ms/step - psnr: 34.5566 - ssim: 0.8834 - mse: 86.5165 - mae: 4.1657 - sobel_loss: 1793.8540 - loss: 4.6978 - val_psnr: 31.2565 - val_ssim: 0.8790 - val_mse: 80.6900 - val_mae: 4.0700 - val_sobel_loss: 1720.7124 - val_val_loss: 5.2113\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 6260s 626ms/step - psnr: 34.5791 - ssim: 0.8838 - mse: 86.0150 - mae: 4.1529 - sobel_loss: 1782.4614 - loss: 4.6826 - val_psnr: 31.2652 - val_ssim: 0.8790 - val_mse: 80.5600 - val_mae: 4.0600 - val_sobel_loss: 1718.0161 - val_val_loss: 5.2068\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 6258s 626ms/step - psnr: 34.5457 - ssim: 0.8837 - mse: 85.8400 - mae: 4.1520 - sobel_loss: 1779.3224 - loss: 4.6831 - val_psnr: 31.2652 - val_ssim: 0.8790 - val_mse: 80.5700 - val_mae: 4.0600 - val_sobel_loss: 1717.7410 - val_val_loss: 5.2128\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 6252s 625ms/step - psnr: 34.5245 - ssim: 0.8835 - mse: 85.8936 - mae: 4.1661 - sobel_loss: 1781.1722 - loss: 4.6934 - val_psnr: 31.2665 - val_ssim: 0.8790 - val_mse: 80.5200 - val_mae: 4.0700 - val_sobel_loss: 1716.7377 - val_val_loss: 5.2064\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 6256s 626ms/step - psnr: 34.5545 - ssim: 0.8833 - mse: 86.2570 - mae: 4.1629 - sobel_loss: 1785.8508 - loss: 4.6966 - val_psnr: 31.2565 - val_ssim: 0.8790 - val_mse: 80.7200 - val_mae: 4.0700 - val_sobel_loss: 1722.1166 - val_val_loss: 5.2098\n",
      "Epoch 0080 --- Learning rate reduced to: 6.24999984211172e-06\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 6259s 626ms/step - psnr: 34.5792 - ssim: 0.8840 - mse: 85.8856 - mae: 4.1472 - sobel_loss: 1778.3604 - loss: 4.6747 - val_psnr: 31.2689 - val_ssim: 0.8791 - val_mse: 80.5000 - val_mae: 4.0600 - val_sobel_loss: 1716.3632 - val_val_loss: 5.2052\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 6261s 626ms/step - psnr: 34.5808 - ssim: 0.8839 - mse: 85.4573 - mae: 4.1396 - sobel_loss: 1770.6132 - loss: 4.6656 - val_psnr: 31.2645 - val_ssim: 0.8791 - val_mse: 80.5900 - val_mae: 4.0600 - val_sobel_loss: 1717.3224 - val_val_loss: 5.2048\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 6260s 626ms/step - psnr: 34.5754 - ssim: 0.8837 - mse: 86.0904 - mae: 4.1588 - sobel_loss: 1782.1379 - loss: 4.6818 - val_psnr: 31.2610 - val_ssim: 0.8790 - val_mse: 80.6300 - val_mae: 4.0700 - val_sobel_loss: 1718.7883 - val_val_loss: 5.2057\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 6263s 626ms/step - psnr: 34.5800 - ssim: 0.8840 - mse: 85.6952 - mae: 4.1518 - sobel_loss: 1775.4170 - loss: 4.6730 - val_psnr: 31.2631 - val_ssim: 0.8790 - val_mse: 80.6000 - val_mae: 4.0600 - val_sobel_loss: 1717.8979 - val_val_loss: 5.2078\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 6259s 626ms/step - psnr: 34.5676 - ssim: 0.8839 - mse: 85.5048 - mae: 4.1461 - sobel_loss: 1770.5236 - loss: 4.6713 - val_psnr: 31.2669 - val_ssim: 0.8790 - val_mse: 80.5400 - val_mae: 4.0600 - val_sobel_loss: 1716.8101 - val_val_loss: 5.2091\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 6258s 626ms/step - psnr: 34.5816 - ssim: 0.8843 - mse: 85.1888 - mae: 4.1347 - sobel_loss: 1764.9202 - loss: 4.6595 - val_psnr: 31.2667 - val_ssim: 0.8790 - val_mse: 80.5800 - val_mae: 4.0600 - val_sobel_loss: 1717.0125 - val_val_loss: 5.2067\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 6268s 627ms/step - psnr: 34.5796 - ssim: 0.8840 - mse: 85.2595 - mae: 4.1402 - sobel_loss: 1765.8812 - loss: 4.6631 - val_psnr: 31.2660 - val_ssim: 0.8791 - val_mse: 80.5100 - val_mae: 4.0700 - val_sobel_loss: 1717.1818 - val_val_loss: 5.2087\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 6261s 626ms/step - psnr: 34.5821 - ssim: 0.8840 - mse: 85.4495 - mae: 4.1374 - sobel_loss: 1768.5092 - loss: 4.6654 - val_psnr: 31.2680 - val_ssim: 0.8790 - val_mse: 80.5200 - val_mae: 4.0600 - val_sobel_loss: 1715.9280 - val_val_loss: 5.2015\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 6258s 626ms/step - psnr: 34.5916 - ssim: 0.8840 - mse: 85.6510 - mae: 4.1426 - sobel_loss: 1773.3962 - loss: 4.6715 - val_psnr: 31.2619 - val_ssim: 0.8791 - val_mse: 80.6100 - val_mae: 4.0700 - val_sobel_loss: 1718.5598 - val_val_loss: 5.2023\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 6258s 626ms/step - psnr: 34.6101 - ssim: 0.8844 - mse: 85.2244 - mae: 4.1272 - sobel_loss: 1764.5900 - loss: 4.6556 - val_psnr: 31.2674 - val_ssim: 0.8791 - val_mse: 80.5100 - val_mae: 4.0600 - val_sobel_loss: 1717.3555 - val_val_loss: 5.2026\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 6257s 626ms/step - psnr: 34.5880 - ssim: 0.8841 - mse: 85.4926 - mae: 4.1440 - sobel_loss: 1770.5106 - loss: 4.6691 - val_psnr: 31.2675 - val_ssim: 0.8790 - val_mse: 80.5300 - val_mae: 4.0600 - val_sobel_loss: 1716.5128 - val_val_loss: 5.2074\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 6259s 626ms/step - psnr: 34.5739 - ssim: 0.8842 - mse: 85.4821 - mae: 4.1449 - sobel_loss: 1770.4178 - loss: 4.6704 - val_psnr: 31.2680 - val_ssim: 0.8791 - val_mse: 80.5200 - val_mae: 4.0700 - val_sobel_loss: 1717.0746 - val_val_loss: 5.2078\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 6264s 626ms/step - psnr: 34.6204 - ssim: 0.8844 - mse: 84.8457 - mae: 4.1226 - sobel_loss: 1756.8293 - loss: 4.6491 - val_psnr: 31.2664 - val_ssim: 0.8791 - val_mse: 80.5700 - val_mae: 4.0700 - val_sobel_loss: 1717.4465 - val_val_loss: 5.2022\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 6266s 627ms/step - psnr: 34.5898 - ssim: 0.8842 - mse: 85.4693 - mae: 4.1408 - sobel_loss: 1770.0226 - loss: 4.6688 - val_psnr: 31.2649 - val_ssim: 0.8790 - val_mse: 80.5600 - val_mae: 4.0700 - val_sobel_loss: 1717.2599 - val_val_loss: 5.2067\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 6263s 626ms/step - psnr: 34.5551 - ssim: 0.8839 - mse: 85.5571 - mae: 4.1478 - sobel_loss: 1772.1670 - loss: 4.6739 - val_psnr: 31.2667 - val_ssim: 0.8791 - val_mse: 80.5600 - val_mae: 4.0600 - val_sobel_loss: 1716.7859 - val_val_loss: 5.2067\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 6268s 627ms/step - psnr: 34.5816 - ssim: 0.8840 - mse: 85.8927 - mae: 4.1491 - sobel_loss: 1777.8094 - loss: 4.6762 - val_psnr: 31.2653 - val_ssim: 0.8790 - val_mse: 80.5600 - val_mae: 4.0700 - val_sobel_loss: 1717.4324 - val_val_loss: 5.2085\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 6379s 638ms/step - psnr: 34.5717 - ssim: 0.8840 - mse: 85.4697 - mae: 4.1424 - sobel_loss: 1768.5198 - loss: 4.6709 - val_psnr: 31.2639 - val_ssim: 0.8791 - val_mse: 80.6200 - val_mae: 4.0600 - val_sobel_loss: 1718.7097 - val_val_loss: 5.2035\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 6412s 641ms/step - psnr: 34.5650 - ssim: 0.8840 - mse: 85.4885 - mae: 4.1416 - sobel_loss: 1769.6426 - loss: 4.6672 - val_psnr: 31.2613 - val_ssim: 0.8791 - val_mse: 80.6300 - val_mae: 4.0700 - val_sobel_loss: 1719.3069 - val_val_loss: 5.2071\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 6425s 643ms/step - psnr: 34.5608 - ssim: 0.8841 - mse: 85.5720 - mae: 4.1427 - sobel_loss: 1772.8956 - loss: 4.6719 - val_psnr: 31.2649 - val_ssim: 0.8790 - val_mse: 80.5800 - val_mae: 4.0700 - val_sobel_loss: 1717.6155 - val_val_loss: 5.2082\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 6413s 641ms/step - psnr: 34.5615 - ssim: 0.8839 - mse: 85.6937 - mae: 4.1511 - sobel_loss: 1772.8002 - loss: 4.6749 - val_psnr: 31.2672 - val_ssim: 0.8791 - val_mse: 80.5300 - val_mae: 4.0700 - val_sobel_loss: 1717.0006 - val_val_loss: 5.2061\n",
      "Ends training\n"
     ]
    }
   ],
   "source": [
    "# Metrics for model evaluation\n",
    "METRICS = [\n",
    "    ctes.METRIC_FUNCTIONS.PSNR,\n",
    "    ctes.METRIC_FUNCTIONS.SSIM,\n",
    "    ctes.METRIC_FUNCTIONS.SSIM_MS, # ---- https://github.com/tensorflow/tensorflow/issues/33840\n",
    "                                   #      MODIFIED ARGUMENTS IN SSIM MULTISCALE (lib.custom_metric_functions.py)\n",
    "    ctes.METRIC_FUNCTIONS.MSE,\n",
    "    ctes.METRIC_FUNCTIONS.MAE,\n",
    "    ctes.METRIC_FUNCTIONS.SOBEL\n",
    "]\n",
    "\n",
    "# Metrics for saving model's checkpoints\n",
    "METRICS_CHECKPOINTS = [\n",
    "    (ctes.METRICS_ALL.PSNR, ctes.METRICS_ALL.VAL_PSNR, 'max'),\n",
    "    (ctes.METRICS_ALL.SSIM, ctes.METRICS_ALL.VAL_SSIM, 'max'),\n",
    "    # (ctes.METRICS_ALL.SOBEL, ctes.METRICS_ALL.VAL_SOBEL, 'min')\n",
    "]\n",
    "\n",
    "# Define training hyperparameters\n",
    "INITIAL_LEARNING_RATE = 0.0001 # 1e-4\n",
    "\n",
    "NUM_EPOCHS = 100 # Nº máximo de iteraciones de entrenamiento: 1.000.000 -- Como antes definimos una época como 10.000 iteraciones (repetir 200 veces el dataset de 800 imágenes dividio en batches de 16)\n",
    "                 # 1.000.000 de iteraciones serán 100 épocas\n",
    "\n",
    "OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=INITIAL_LEARNING_RATE)\n",
    "LOSS_FUNCTION = train.get_loss_function(ctes.LOSS_FUNCTIONS.MAE)\n",
    "\n",
    "# Define callbacks\n",
    "\n",
    "# Se indica en el paper original, y se aplica en la implementación en TF 1.13, que cada 200.000 iteraciones, el learning rate se debe reducir a la mitad\n",
    "# Estableciendo que una época se compone de 200 repeticiones del dataset de entrenamiento para conseguir 10.000 iteraciones, cada 20 'épocas' se deberá reducir a la mitad el learning rate\n",
    "\n",
    "learning_rate_scheduler_callback = tf.keras.callbacks.LearningRateScheduler(callbacks.create_scheduler_function(20, 0.5)) # Cada 20 épocas, multiplicar lr por 0.5\n",
    "\n",
    "# Model checkpoints callbacks\n",
    "checkpoint_callbacks = [tf.keras.callbacks.ModelCheckpoint(save_path + model_name + '_best_' + mtr[0] + '.h5',\n",
    "                                                           monitor=mtr[1],\n",
    "                                                           save_best_only=True,\n",
    "                                                           mode=mtr[2],\n",
    "                                                           save_weights_only=True) for mtr in METRICS_CHECKPOINTS]\n",
    "\n",
    "# Save training metrics evolution callback\n",
    "metrics_evolution_callback = callbacks.Save_Training_Evolution(save_metrics_path + model_name_for_metrics + '_evolution.csv')\n",
    "\n",
    "\n",
    "CBACKS = [learning_rate_scheduler_callback, checkpoint_callbacks, metrics_evolution_callback] \n",
    "\n",
    "\n",
    "# TRAIN\n",
    "model.compile(optimizer=OPTIMIZER,\n",
    "#               loss=LOSS_FUNCTION,\n",
    "              # SSIM_MS needs greater images than training patches, so ignore this metric on training\n",
    "              metrics=[train.get_metric_function(x) for x in METRICS if x != ctes.METRIC_FUNCTIONS.SSIM_MS])\n",
    "\n",
    "print('Starts training')\n",
    "model.fit(train.dataset, epochs=NUM_EPOCHS, verbose=1, validation_data=val.dataset, callbacks=CBACKS)\n",
    "print('Ends training')\n",
    "\n",
    "'''\n",
    "Starts training --- CUANDO SE CALCULABA SOBRE LAS LR\n",
    "Epoch 1/100\n",
    " 3566/10000 [=========>....................] - ETA: 1:06:45 - loss: 2.2201 - psnr: 41.8648 - ssim: 0.9845 - mse: 45.8110 - mae: 1.5339 - sobel_loss: 253.4401\n",
    "'''\n",
    "\n",
    "with open('ended_scripts.txt', 'a') as f:\n",
    "    f.write(FILENAME + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "center-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('TRAINED_MODELS_NEW/RCAN-SCALE3/model_loss-computed-on-lr-an_last_epoch.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit6c4dec2e42734bc298ce0c3bfcfccb75"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
